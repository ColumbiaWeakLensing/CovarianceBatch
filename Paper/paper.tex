%\documentclass[useAMS, usenatbib,usegraphicx,letter]{mn2e}
%\documentclass[11pt]{article}
\documentclass[reprint,aps,prd,superscriptaddress,showkeys,showpacs]{revtex4-1}
\usepackage{epsfig,amsmath,natbib}

\usepackage{aas_macros}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{hyperref}
\usepackage{color}
\usepackage{pbox}
\usepackage{booktabs}
\usepackage[dvipsnames]{xcolor}

\hypersetup{
	colorlinks=false,
	citecolor=green
}
% \usepackage{graphicx}
% \usepackage{epstopdf}
% \usepackage{natbib}

%%%%%%%%%%%%%%%%%
%Custom commands%
%%%%%%%%%%%%%%%%%

\newcommand{\bb}[1]{\mathbf{#1}}
\newcommand{\bbh}[1]{\mathbf{\hat{#1}}}
\newcommand{\h}[1]{\hat{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Simulating cosmic variance in Weak Lensing: effects on parameter inferences}

\author{Andrea Petri}
\email{apetri@phys.columbia.edu}
\affiliation{Department of Physics, Columbia University, New York, NY 10027, USA}
\affiliation{Physics Department, Brookhaven National Laboratory, Upton, NY 11973, USA}

\author{Zolt\'an Haiman}
\affiliation{Department of Astronomy, Columbia University, New York, NY 10027, USA}

\author{Morgan May}
\affiliation{Physics Department, Brookhaven National Laboratory, Upton, NY 11973, USA}

\date{\today}

\label{firstpage}

\begin{abstract}
Constraining cosmology using Weak Gravitational Lensing consists in comparing measured features with simulated ones. An accurate estimate of the feature covariance matrix is essential to obtain accurate parameter confidence intervals. When this covariance matrix $\bb{C}$ is measured from simulations, an important question to ask is how big the simulation set should be for an accurate estimation of $\bb{C}$. We construct different mock ensembles with $N_r$ realizations of the same shear field, based on $N_s<N_r$ independent $N$--body simulations. Using the shear--shear power spectrum as a summary statistic, we find that a single $N$--body simulation can be recycled a large number of times to produce an ensemble of $N_r=10^5$ shear realizations that are mutually independent.       
\end{abstract}


\keywords{Weak Gravitational Lensing --- Simulations --- Methods: numerical,statistical}
\pacs{98.80.-k, 95.36.+x, 95.30.Sf, 98.62.Sb}

\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%% INTRO %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
%
Weak Gravitational lensing is a promising cosmological probe for constraining the Dark Energy equation of state $w$, and has been considered by a range of past (CFHTLens \citep{cfht1,cfht2}), current (DES \citep{DES}) and future (LSST \citep{LSST}) experiments. In an era where cosmology is becoming data driven, accurate numerical simulations of shear fields are becoming important for a number of reasons including the study of baryonic effects \citep{BaryonXiuyuan}, non--Gaussian statistics \citep{PeaksJan,MinkJan,MinkPetri} and various systematics. Building cosmological predictions from simulations naturally introduces fluctuations in the forecasts, mainly due to cosmic variance. These fluctuations have been shown to have non negligible effects on estimates of features covariance matrices and hence on parameter constraints (see \citep{DodelsonSchneider13}). This work studies this issue further, focusing on the number of independent $N$--body simulations that is necessary to run for obtaining accurate estimates of parameter constraints, with particular focus on $w$. This paper is organized as follows: in the first paragraph we briefly describe the shear simulation methods we used, as well as the formalism we adopted to compute cosmological parameter constraints. We then outline our main findings and discuss the results, as well as future prospects for continuing this study.  

%%%%%%%%%%%%%%%%%%% METHODS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Methods}

\subsection{Shear field simulations}
\label{shearsim}
%
In this paragraph we describe how we constructed our shear field ensembles. Background galaxies at redshift $z_s$ are lensed by large scale structure between $z=0$ and $z_s$. The shape distortions due to the cosmic shear $\pmb{\gamma}$ can be computed in terms of the dark matter gravitational potential $\Phi(\bb{x},z)$. Because the evolution of $\Phi$ in redshift is non--linear, its evolution needs to be computed with numerical simulations. We make use of the public code \texttt{Gadget2} \citep{Gadget2}, with which we run a sequence of dark--matter--only $N$--body simulations that track the evolution of the density fluctuations in the large scale structure of the universe. We assume a standard $\Lambda$CDM framework with $(\Omega_m,\Omega_\Lambda,h,w,\sigma_8,n_s)=(0.26,0.74,0.72,-1,0.8,0.96)$ and we fix the comoving size of the simulation box to $240\mathrm{Mpc}/h$. We fill the box with $512^3$ particles, which correspond to a mass resolution of $10^{10}M_\odot$. We assume a uniform galaxy distribution at a constant redshift $z_s=2$ (at which the simulation box has an angular size of $\theta_{box}=3.5\mathrm{deg}$) and we disctretize the mass distribution between $z_s$ and the observer at $z=0$ with a sequence of 46 two dimensional lenses of thickness $80\mathrm{Mpc}/h$. The surface density on each lens is computed by projecting the three dimensional density measured from \texttt{Gadget2} snapshots. We then apply the multi--lens--plane algorithm (see \citep{RayTracingHartlap,RayTracingJain} for example) to trace the deflections of $n_{ray}^2=2048^2$ light rays arranged on a square grid of total size $\theta_{box}$, from $z=0$ to $z_s$. The light deflection calculations have been performed with our implementation of multi--lens--plane algorithm, which is part of the \texttt{LensTools} computing package \citep{LensTools} (released under the \texttt{MIT} license). Different realizations $r$ of the same shear field $\pmb{\gamma}_r(\pmb{\theta})$ can be generated with different choices of the lenses that lay between the observer and $z_s$. The randomization procedure we adopt is the following:

\begin{itemize}
\item Pick a lens redshift $z_l$, and select the snapshot at $z_l$ from the $i$--th $N$--body simulation at disposal, where $i$ is a random number in $[1,N_s]$
\item Choose randomly a direction between the three choices ${\bb{n}_x,\bb{n}_y,\bb{n}_z}$: the lens plane will be pependicular to this direction
\item Choose the cutting point of the plane in the snapshot: because the lens thickness is 1/3 the size of the box, we can cut three different slices of the simulation box for each orientation ${\bb{n}_x,\bb{n}_y,\bb{n}_z}$
\item Perform a periodical random shift of the lens plane along its two directions
\item Repeat this procedure for each lens redshift $z_l$  
\end{itemize}  
%
This randomization procedure allows us to produce an arbitrary number $N_r$ of mock shear realizations $\pmb{\gamma}_r(\pmb{\theta})$, which however will not be all independent if $N_s$ is not large enough. Using a set of 200 independent $N$--body simulations, we construct different ensembles with different choices of $N_s\in[1,200]$, each made of 1000 mock shear realizations. We also build an additional ensemble with $N_s=1$ and $10^5$ mocks. From each of these mocks we reconstruct the convergence $\kappa_r(\pmb{\theta})$ and measure its angular power spectrum $P^{\kappa\kappa}_r(l)$ defined as
\begin{equation}
\langle\tilde{\kappa}_r(\bb{l})\tilde{\kappa}_r(\bb{l}')\rangle = (2\pi)^2\delta_D(\bb{l}+\bb{l}')P^{\kappa\kappa}_r(l)
\end{equation}
%
As an additional summary statistic, we consider the counts of local $\kappa$ maxima of a certain height $\kappa_0$, $n_r(\kappa_0)$ (from now on \textit{peak counts}), with varying $\kappa_0$. The fact that the ensemble of $N_r$ mocks is not completely independent if $N_s$ is not large enough can have an effect on the covariance estimators of $P^{\kappa\kappa},n(\kappa_0)$. 


\subsection{Parameter inference}
%
Let $\bbh{d}$ a feature of dimension $N_b$, $\bb{d}(\bb{p})$ be the smooth expectation of this feature at a point $\bb{p}$ in parameter space (which has a dimension $N_p$) and $\bb{C}$ be the $N_b\times N_b$ feature covariance matrix. For the purpose of this work $\bb{p}$ is the triplet $(\Omega_m,w,\sigma_8)$ and $\bb{d}$ is one of the features listed in Table \ref{featuretable}. While, in some cases, $d(\bb{p})$ can usually be predicted reasonably accurately by already existing emulators (see \citep{coyote2,Nicaea} for example), the matter is more complicated for covariance matrices. Estimating $\bb{C}$ from simulations involves generating a series of mock realizations $\bbh{d}_r$ with $r=1...N_r$ and estimating the sample covariance $\bbh{C}$

\begin{equation}
\bb{\bar{d}} = \frac{1}{N_r}\sum_{r=1}^{N_r} \bbh{d}_r
\end{equation}

\begin{equation}
\label{covest}
\bbh{C} = \frac{1}{N_r-1}\sum_{r=1}^{N_r} (\bbh{d}_r - \bar{\bb{d}}) (\bbh{d}_r - \bar{\bb{d}})^T
\end{equation}
%
Assuming a normal feature likelihood, together with a flat prior on the parameter space, the parameter posterior distribution $\mathcal{L}(\bb{p}\vert\bbh{d}_{obs})$ given an observed instance of $\bbh{d}$, which we call $\bbh{d}_{obs}$, can be obtained using Bayes theorem
\begin{equation}
\label{posteriorbayes}
-2\log\mathcal{L}(\bb{p}\vert\bbh{d}_{obs}) = (\bbh{d}_{obs}-\bb{d}(\bb{p}))^T\bbh{C}^{-1}(\bbh{d}_{obs}-\bb{d}(\bb{p}))
\end{equation}
%
For the sake of simplicity, we approximate the posterior as a Gaussian around its maximum. This is easily done approximating the simulated feature at first order around a point $\bb{p}_0$ (that ideally is the maximum of (\ref{posteriorbayes}))
\begin{equation}
\bb{d}(\bb{p}) \approx \bb{d}_0 + \bb{d}_0^\prime(\bb{p}-\bb{p}_0) 
\end{equation}
%
To measure the feature derivatives $\bb{d}'_0$ with respect to cosmology, we make use of the public code \texttt{NICAEA} \citep{Nicaea} for the power spectrum, and we use an independent simulation set (that contains mocks at different combinations of $(\Omega_m,w,\sigma_8)$) for the peak counts.
We can build the estimator for the posterior maximum $\bbh{p}$, given the observation $\bbh{d}_{obs}$, as follows:
%
\begin{equation}
\label{estimatormean}
\bbh{p} = \bb{p}_0 + \bbh{T}(\bbh{d}_{obs}-\bb{d}_0)
\end{equation}

\begin{equation}
\bbh{T} = (\bb{d}_0'^T\bbh{C}^{-1}\bb{d}_0')^{-1}\bb{d}_0'^T\bbh{C}^{-1}
\end{equation}
%
Because $\bbh{p}$ is estimated using a noisy data instance $\bbh{d}_{obs}$, its estimate will be scattered around the true value $\langle\bbh{p}\rangle_O$. In the following we use the $\langle\rangle_O$ notation for expectation values taken with respect to observations, while we keep the notation $\langle\rangle$ for expectation values taken with respect to the simulations. Defining the \textit{precision matrix} $\bbh{\Psi}=\bbh{C}^{-1}$, we can express the estimator of the observational scatter in $\bbh{p}$

\begin{equation}
\label{estimatorcovariance}
\h{\Sigma}_\bb{p} = \bbh{F}^{-1}\bb{d}_0'^T\bbh{\Psi}\langle(\bbh{d}_{obs}-\bb{d}_0)(\bbh{d}_{obs}-\bb{d}_0)^T\rangle_O\bbh{\Psi}\bb{d}_0'\bbh{F}^{-1}
\end{equation}

\begin{equation}
\label{estimatorfisher}
\bbh{F} = \bb{d}_0'^T\bbh{\Psi}\bb{d}_0'
\end{equation}
%
Where we introduced the Fisher matrix estimator $\bbh{F} = \bb{d}_0'^T\bbh{\Psi}\bb{d}_0'$ and, for simplicity, we assumed $\langle\bbh{d}_{obs}\rangle_O=\bb{d}_0$, so that $\langle(\bbh{d}_{obs}-\bb{d}_0)(\bbh{d}_{obs}-\bb{d}_0)^T\rangle_O=\bb{C}$. 
When we perform an observation $\bbh{d}_{obs}$, the parameter estimate $\bbh{p}$ is a random draw from a probability distribution with variance $\h{\Sigma}_\bb{p}$, which inherits noise from the simulations. In the following we review the method to compute $\langle\h{\Sigma}_\bb{p}\rangle$ \citep{DodelsonSchneider13,Taylor12}. The noise in the covariance estimator (\ref{covest}) and its inverse $\bbh{\Psi}$ propagates all the way to the posterior (\ref{posteriorbayes}), the parameter estimate (\ref{estimatormean}) and its variance (\ref{estimatorcovariance}). Following \citep{Taylor12} we can say that, if the feature vector $\bbh{d}_r$ from which $\bbh{C}$ is estimated is drawn from a multivariate Gaussian distribution, the precision matrix estimator $\bbh{\Psi}$ is biased
\begin{equation}
\label{psibias}
\langle\bbh{\Psi}\rangle = \frac{N_r-1}{N_r-N_b-2}\bb{\Psi}
\end{equation}
%
and, once the bias is corrected, the residual fluctuations in $\bbh{\Psi}$ are correlated as follows
\begin{equation}
\label{psifluctuations}
\langle\delta\h{\Psi}_{ij}\delta\h{\Psi}_{kl}\rangle = A\Psi_{ij}\Psi_{kl} + B(\Psi_{ik}\Psi_{jl} + \Psi_{il}\Psi_{jk})
\end{equation}
%
where $A,B$ are constants that depend on $N_r,N_b$ and have the asymptotic behavior $A\propto1/N_r^2,B\propto1/N_r$. We want to estimate the effect of these fluctuations on the parameter constraints $\Sigma_\bb{p}$, following the guidelines of \citep{DodelsonSchneider13}. We consider three cases:
\begin{enumerate}
\item If the true data covariance $\bb{C}$ is known, the estimator (\ref{estimatorcovariance}) is biased, and the dominant contribution of the bias comes from the second order fluctuations in $\bbh{\Psi}$. Once the expectation values are taken as in (\ref{psifluctuations}), the bias sums up to 

\begin{equation}
\label{dodelsonscaling}
\langle\h{\Sigma}_\bb{p}\rangle=\Sigma_\bb{p}(1+B(N_b-N_p))
\end{equation}
%
This is the result obtained by \citep{DodelsonSchneider13}.

\item Usually the true covariance is not known, and it is tempting to plug in its estimator $\bbh{C}$, measured from the same simulation set we use to compute $\bbh{\Psi}$. This approach has been used before in the literature (see \citep{MinkPetri,MinkShirasaki} for example). If we do that, and we do not correct for the bias (\ref{psibias}), the parameter variance will have a contribution from both the second and first order fluctuations in $\bbh{\Psi}$, which now have a non zero expectation value. In this case the bias sums up to 
\begin{equation}
\label{mockscalinguncorrected}
\langle\h{\Sigma}_\bb{p}\rangle=\Sigma_\bb{p}(1-(1+N_b)/N_r+B(1+N_p))
\end{equation}

\item If we repeat the same exercise as above, but we correct for the bias in the precision matrix estimator, we are left with 

\begin{equation}
\label{mockscalingcorrected}
\langle\h{\Sigma}_\bb{p}\rangle=\Sigma_\bb{p}(1+B(1+N_p))
\end{equation}

\end{enumerate} 
%
The complete calculations that justify (\ref{dodelsonscaling}),(\ref{mockscalinguncorrected}) and (\ref{mockscalingcorrected}) are shown in the Appendix. With the $\bbh{d}_r$ Gaussianity assumption, the coefficient $B$ can be calculated exactly as \citep{DodelsonSchneider13,Taylor12}, and tends to $1/N_r$ in the limit of $N_r\gg N_b$. This leads to a degradation of order $D/N_r$ for the variance of each estimated parameter $\sigma^2_p=\Sigma_{pp}$, where $D=N_b-N_p,N_p-N_b,1+N_p$ for cases 1,2,3 respectively. This means that, when parameter errors are estimated purely from simulations, and the same simulation set is used to estimate both $\bbh{C},\bbh{\Psi}$, these errors tend to decrease with $N_b$ (case 2), or at best remain constant (case 3), while the distribution of $\bbh{p}$ has still a variance that increases with $N_b$. This typically leads to underestimates in parameter errors. We test the scaling relation
\begin{equation}
\label{ourscaling}
\langle\h{\sigma}_p^2\rangle = \sigma^2_p(N_s)\left(1+\frac{D}{N_r}\right)
\end{equation}
%
on our simulations. We call $D$ the \textit{effective dimensionality} of the feature space. We compute the expectation values of $\h{\sigma}^2_p$ (equations (\ref{estimatorcovariance}),(\ref{ourscaling})) averaging over 100 random resamplings of our shear ensembles. For the true feature covariance matrix $\langle(\bbh{d}-\bb{d}_0)(\bbh{d}-\bb{d}_0)^T\rangle=\bb{C}$ we use the estimated covariance from a grand ensemble built with the union of all the ensembles with different $N_s$. 

The true parameter variance $\sigma^2_p(N_s)$ in principle depends on the number of independent $N$--body simulations $N_s$, which appears in the randomization procedure we describe in \S~\ref{shearsim}. The reason for this can be found in that, if $N_s$ is not big enough, the different shear realizations cannot be all independent, and hence the true variance $\sigma^2_p(N_s\rightarrow\infty)$ cannot be recovered in the limit $N_r\rightarrow\infty$. In particular there could be some residual error in the expectation value of (\ref{estimatorcovariance}) even if $N_r$ is big. In the next paragraph we outline our main findings.
 

%%%%%%%%%%%%%%%%%%% RESULTS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}
\includegraphics[scale=0.4]{Figures/ps_pdf.eps}
\caption{PDF of the $\kappa$ power spectrum,$\mathcal{L}(P_l^{\kappa\kappa})$, at four selected multipoles $l=115,344,1349,5283$, for different shear ensembles constructed with $N_s=$1 (black), 2 (blue), 5 (green), 50 (red), 100 (purple). The thick black lines correspond to an ensemble generated with $N_s=1$ and $10^5$ mock realizations.}
\label{ps_pdf}
\end{figure*}

\begin{figure}
\includegraphics[scale=0.3]{Figures/ps_variance.eps}
\caption{Variance of the $\kappa$ power spectrum as a function of the multipole $l$, in units of the expected gaussian variance from equation (\ref{gaussianvar}). The variance is measured from different shear ensembles with $N_s=$1 (black), 2 (blue), 5 (green), 10 (red), 50 (purple), 100 (orange). }
\label{ps_var}
\end{figure}

\begin{figure}
\includegraphics[scale=0.3]{Figures/scaling_nr.eps}
\caption{Bias in the $w$ variance, $\langle\h{\sigma}^2_w\rangle$, as a function of the number of mock realizations $N_r$ used in the feature covariance estimator (\ref{covest}). Results for different mock ensembles generated with $N_s=$1 (black), 2 (blue), 5 (green), 50 (red), 100 (purple) are shown. The figure shows both the measured trends (solid lines) and their best fits according to equation (\ref{ourscaling}). The thick black line correspond to an ensemble generated with $N_s=1$ and $10^5$ mock realizations. }
\label{wvar_nr}
\end{figure}

\begin{figure}
\includegraphics[scale=0.3]{Figures/scaling_ns.eps}
\caption{Variance on $w$ in the limit $N_r\rightarrow\infty$, varying the mock ensemble used to compute the covariance estimator (\ref{covest}). We show the dependence of $\sigma_0^2(N_s)$ in units of the mean over $N_s$, for the power spectrum logarithmically binned (black), the power spectrum linearly binned (red) and the peak counts (green).}
\label{wvar_ns}
\end{figure}

\begin{table*}
\begin{center}
\begin{tabular}{ccccc}
\toprule
\textbf{Feature} &  \textbf{Specifications} & $N_b$ &  \textbf{Symbol} & \textbf{Color} \\ \hline \hline
\midrule
Power Spectrum, log binning  & $l \in [100,800] $ & 8 & $\times$ & black  \\ 
Power Spectrum, log binning  & $l \in [1000,6000] $ & 7 & $\times$ & black  \\ 
Power Spectrum, log binning  & $l \in [100,6000] $ & 15 & $\times$ & black  \\
Power Spectrum, linear binning  & $l \in [100,2000] $ & 15 & \textcolor{red}{$+$} & \textcolor{red}{red}  \\ 
Power Spectrum, linear binning  & $l \in [2500,4500] $ & 15 & \textcolor{red}{$\times$} & \textcolor{red}{red}  \\
Power Spectrum, linear binning  & $l \in [100,4500] $ & 30 & \textcolor{red}{$\bullet$} & \textcolor{red}{red}  \\ 
Power Spectrum, linear binning  & $l \in [100,6000] $ & 39 & \textcolor{red}{$\bullet$} & \textcolor{red}{red}  \\ \hline
Low peaks  & $\kappa_0 \in [-0.06,0.09] $ & 15 & \textcolor{OliveGreen}{$+$} & \textcolor{OliveGreen}{green}  \\ 
Intermediate peaks  & $\kappa_0 \in [0.1,0.27] $ & 15 & \textcolor{OliveGreen}{$\bigstar$} & \textcolor{OliveGreen}{green}  \\ 
High peaks  & $\kappa_0 \in [0.28,0.45] $ & 15 & \textcolor{OliveGreen}{$\diamond$} & \textcolor{OliveGreen}{green}  \\
Low+Intermediate peaks  & $\kappa_0 \in [-0.06,0.27] $ & 30 & \textcolor{OliveGreen}{$\times$} & \textcolor{OliveGreen}{green}  \\
Intermediate+High peaks  & $\kappa_0 \in [0.1,0.45] $ & 30 & \textcolor{OliveGreen}{$\bullet$} & \textcolor{OliveGreen}{green}  \\
All peaks  & $\kappa_0 \in [-0.06,0.45] $ & 45 & \textcolor{OliveGreen}{$\blacksquare$} & \textcolor{OliveGreen}{green}  \\ \hline
\bottomrule
\end{tabular}
\end{center}
\caption{Catalog of feature types used in this work, along with the chosen number of bands $N_b$ and the plot legends for Figure \ref{curvingnb}.}
\label{featuretable}
\end{table*}

\begin{figure}
\includegraphics[scale=0.3]{Figures/curving_nb.eps}
\caption{Expectation value of the $w$ variance computed with equation (\ref{estimatorcovariance}) as a function of $1/N_r$, for the features outlined in Table \ref{featuretable}. The line width increases with the number of bands $N_b$ used for each feature.}
\label{curvingnb}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this section we outline the main results of this work. We show the qualitative behavior of the $P^{\kappa\kappa}$ probability distribution function (PDF) in ensembles built with different $N_s$. We also show how the forecasts on the Dark Energy equation of state, $w$, depend on $N_s$ and $N_r$. Figure \ref{ps_pdf} shows the power spectrum PDF at four selected multipoles, while Figure \ref{ps_var} shows the variance in each multipole. This result is compared to the one that we would obtain assuming that the convergence is a Gaussian random field
\begin{equation}
\label{gaussianvar}
\mathrm{Var}(P^{\kappa\kappa}(l)) = \frac{P^{\kappa\kappa,2}(l)}{N_{eff}(l)}
\end{equation}
%
where $N_{eff}(l)$ is the number of independent modes used to estimate the power spectrum at $l$. To measure $P^{\kappa\kappa}(l),N_{eff}(l)$, we compute the real Fourier transform of the pixelized map $\kappa_r(\pmb{\theta})$ with the FFT algorithm. Each Fourier pixel $(i_x,j_y)$ corresponds to a mode $(l_x,l_y)=2\pi(i_x,i_y)/\theta_{box}$, with $i_x=-n_{ray}/2,...,n_{ray}/2$ and $i_y=0,...,n_{ray}/2$. We count the number of pixels $N(l)$ that fall inside a multipole bin $(l_1,l_2)$. Because the $\kappa$ field is real, the modes $(\pm l_x,0)$ are not independent. If we let $N(l,l_y=0)$ be the number of non--independent modes, the mode counting for the variance should be corrected as 

\begin{equation}
N_{eff}(l) = \frac{N^2(l)}{N(l)+N(l,l_y=0)}
\end{equation}
%
We not that this correction is important at low $l$ only, where pixelization effects are more important. In other words $N_{eff}(l\gg2\pi/\theta_{box})\approx N(l)$. 

Figure \ref{wvar_nr} show the scaling of the expectation value of $\h{\sigma}_w^2$ with the number of mocks $N_r$ using the power spectrum and compare it with the known result obtained in \citep{DodelsonSchneider13} and expressed in equation (\ref{ourscaling}). Figure \ref{wvar_ns} shows the effect of varying $N_s$ on the $w$ constraint. Finally Figure \ref{curvingnb} shows.... 

%%%%%%%%%%%%%%%%%% DISCUSSION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}

In this section we discuss our main findings. Figure \ref{ps_pdf} shows that, although different choices of $N_s$ do not seem to affect the power spectrum PDF at large scales (top two panels), there are some qualitative differences on small scales (bottom two panels), on which a shear ensemble built with a small $N_s$ does not have the same statistical behavior of ensembles built with large $N_s$. Looking at the black curves, we see that the $N_s=1$ ensembles exibit some stochastic fluctuations in where the PDF peaks. We need as small as $N_s=2$ to recover the right location parameter for the power spectrum on small scales. 

Figure \ref{ps_var} shows the variance of convergence power spectrum computed from different ensembles, in units of the Gaussian expectation. We find that, even with $N_s=1$, our results are in good agreement with the ones obtained by \citep{Sato12}, which used $N_s=400$. This fact by itself is not sufficient to conclude that $N_s$ does not have an effect on parameter inferences, since these depend on the cross band covariances. 

In Figure \ref{wvar_nr} we examine how the $w$ constraint depends on the number of mocks used to estimate the covariance, and we find good agreement with (\ref{ourscaling}). In particular we can see that one $N$--body simulation is enough to construct an ensemble of $O(10^5)$ mutually independent mock power spectra, for which the $w$ constraint scales like $1/N_r$ all the way to $N_r=10^5$.    

Figure \ref{wvar_ns} shows the dependence of the dark energy constraint with $N_s$. We find that, in the range $N_s\in[1,200]$ the $w$ inferred variance $\sigma_0^2$ fluctuates stochastically and does not show an appreciable trend with $N_s$. 



When we estimate the data covariance $\bb{C}$ from the same simulation set used to measure $\bbh{\Psi}$, the effective dimensionality $D$ decreases with increasing $N_b$ in the case where the $\bbh{\Psi}$ bias is corrected, and stays constant when this bias is corrected. This fact that should be taken into considerations when estimating parameter errors purely from simulations, as underestimations might occur. 

%%%%%%%%%%%%%%%%%% CONCLUSION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}

In this work we examine the effect of $N$--body simulations based shear ensembles on forecasted cosmological constraints. Our main results can be summarized as follows:

\begin{itemize}
\item We can recycle a single $N$--body simulation to produce an ensemble of $O(10^5)$ independent maps. The mean feature measured from a shear ensemble, though, could be inaccurate if only one $N$--body simulation is used.  
\item The $1/N_r$ scaling for the dark energy constraint has been verified in our simulations for $N_r\gg 100$ 
\item The fluctuations in the $w$ forecasted variance do not exibit an appreciable trend with $N_s$ 
\end{itemize}
%
Future prospects of this work involve extending this analysis to more general feature spaces, such as the ones that characterize non--Gaussian statistics such as higher moments of $\kappa$ fields, Minkowski Functionals and higher order $\kappa$ correlators. In order to scale these considerations to future surveys such as LSST, it is necessary to see if our findinds hold when challenged by larger and higher resolution $N$--body simulations \citep{Qcontinuum}.   

%%%%%%%%%%%%%%%%%%%%%%%%%% ACKNOWLEDGMENTS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 

\section*{Acknowledgements}

\bibliography{ref}

%%%%%%%%%%%%%%%%%%%%%%%%%% APPENDIX %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Appendix: scaling of the effective dimensionality}
\label{appendix}

The goal of this appendix is giving a derivation of (\ref{dodelsonscaling}),(\ref{mockscalinguncorrected}) and (\ref{mockscalingcorrected}) following the guidelines from \citep{DodelsonSchneider13,Taylor12}. First consider the case in which we use the same simulation set to estimate $\bb{C},\bbh{\Psi}$: in this case equation (\ref{estimatorcovariance}) reduces to the inverse Fisher estimator $\h{\Sigma}_\bb{p}=\bbh{F}^{-1}$. If we write $\bbh{F}=\bb{F}+\delta\bbh{F}=\bb{F}+\bb{d}_0'^T\delta\bbh{\Psi}\bb{d}_0'$, and expand at second order in the fluctuations we get

\begin{equation}
\h{\Sigma}_\bb{p} = \bb{F}^{-1} + \bb{F}^{-1}\left(- \delta{\bbh{F}}+ \delta{\bbh{F}}\bb{F}^{-1}\delta{\bbh{F}}\right)\bb{F}^{-1}  
\end{equation}  
%
If we use the precision estimator $\bbh{\Psi}=\bb{\Psi}+\delta\bbh{\Psi}$ and do not correct for the bias (\ref{psibias}), we have to use the facts that
\begin{equation}
\begin{matrix}
& \langle\delta\bbh{\Psi}\rangle = \frac{1+N_b}{N_r-N_b-2}\bb{\Psi} \\ \\
& \langle\delta\h{\Psi}_{ij}\delta\h{\Psi}_{kl}\rangle = \frac{A([(N_r-1)^2+(1+N_b)^2]\Psi_{ij}\Psi_{kl} + B(N_r-1)^2(\Psi_{ik}\Psi_{kl}+\Psi_{il}\Psi_{jk})}{(N_r-N_b-2)^2}
\end{matrix}
\end{equation}
%
Keeping only the leading order $O(1/N_r)$ in the expansion we get the results
\begin{equation}
\label{explanationuncorrected}
\begin{matrix}
& \langle\delta\bbh{F}\rangle = \left(\frac{1+N_b}{N_r}\right)\bb{F} \\ \\
& \langle\delta{\bbh{F}}\bb{F}^{-1}\delta{\bbh{F}}\rangle = B(1+N_p)\bb{F}
\end{matrix}
\end{equation}
%
which leads immediately to (\ref{mockscalinguncorrected}). Now suppose we correct for the bias in the precision estimator, and use the unbiased $\bbh{\Psi}$ for which $\delta\bbh{\Psi}=0$. This leads to equation (\ref{psifluctuations}) for the quadratic fluctuations in the precision matrix, and to the same (\ref{explanationuncorrected}), except for $\langle\delta\bbh{F}\rangle=0$. This leads to (\ref{mockscalingcorrected}). If now we keep $\bb{C}$ fixed and we estimate only $\bbh{\Psi}$ from the simulations, we get
\begin{equation}
\label{tempcovarianceestimate}
\h{\Sigma}_\bb{p} = (\bbh{F}+\delta\bbh{F})^{-1}\bb{d}_0'^T(\bbh{\Psi}+\delta\bbh{\Psi})\bb{C}(\bbh{\Psi}+\delta\bbh{\Psi})\bb{d}_0'(\bbh{F}+\delta\bbh{F})^{-1}
\end{equation}
%
If we isolate the second order terms in (\ref{tempcovarianceestimate}), the result is 
\begin{equation}
\h{\Sigma}_\bb{p}\vert_2 = \bb{F}^{-1}(\bb{d}_0'^T\delta\bbh{\Psi}\bb{C}\delta\bbh{\Psi}\bb{d}_0'-\delta{\bbh{F}}\bb{F}^{-1}\delta{\bbh{F}})\bb{F}^{-1}
\end{equation} 
%
The expectation values of the quadratic fluctuations are easily computed using (\ref{psifluctuations}):
\begin{equation}
\begin{matrix}
& \langle\bb{d}_0'^T\delta\bbh{\Psi}\bb{C}\delta\bbh{\Psi}\bb{d}_0'\rangle = B(1+N_b)\bb{F} \\ \\
& \langle\delta{\bbh{F}}\bb{F}^{-1}\delta{\bbh{F}}\rangle = B(1+N_p)\bb{F}
\end{matrix}
\end{equation}
%
From which (\ref{dodelsonscaling}) immediately follows. 
\label{lastpage}
\end{document}
